{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c7f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install necessary libraries (Run once)\n",
    "# !pip install numpy pandas spacy scikit-learn tensorflow transformers torch datasets evaluate rouge_score bert_score matplotlib seaborn\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28de4780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.16.0-rc0\n",
      "PyTorch Version: 2.7.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep Learning Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "\n",
    "# Transformers Imports\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "# Metrics\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fdaaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices available: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "✅ MPS/GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for available devices\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices available:\", devices)\n",
    "\n",
    "# Check specifically for GPU/MPS\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n✅ MPS/GPU detected: {gpus}\")\n",
    "else:\n",
    "    print(\"\\n❌ No GPU detected. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03045ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Text...\n",
      "Cleaning Summaries...\n",
      "Final Dataset Size: 98401\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "summary = pd.read_csv('/Users/lovishbhatia/Downloads/Eco/Ankit/news_summary.csv', encoding='iso-8859-1')\n",
    "raw = pd.read_csv('/Users/lovishbhatia/Downloads/Eco/Ankit/news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "# Merge Data\n",
    "pre1 = raw.iloc[:, 0:2].copy()\n",
    "pre2 = summary.iloc[:, 0:6].copy()\n",
    "pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep=\" \"), sep=\" \"), sep=\" \"), sep=\" \")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
    "df['summary'] = pd.concat([pre1['headlines'], pre2['headlines']], ignore_index=True)\n",
    "\n",
    "# Cleaning Function\n",
    "def text_cleaner(text, remove_stopwords=False):\n",
    "    # Convert to string and lowercase\n",
    "    newString = str(text).lower()\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub(r'\"', '', newString)\n",
    "    newString = re.sub(r\"'s\\b\", \"\", newString)\n",
    "    newString = re.sub(r\"[^a-zA-Z]\", \" \", newString)\n",
    "    newString = re.sub(r'[m]{2,}', 'mm', newString)\n",
    "    \n",
    "    # Optimization: Using native split/join is faster than many regexes for spaces\n",
    "    tokens = [w for w in newString.split() if len(w) > 1] # Remove single chars\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply Cleaning\n",
    "print(\"Cleaning Text...\")\n",
    "df['cleaned_text'] = df['text'].apply(text_cleaner)\n",
    "print(\"Cleaning Summaries...\")\n",
    "df['cleaned_summary'] = df['summary'].apply(text_cleaner)\n",
    "\n",
    "# Add Start/End Tokens for LSTM ONLY (Transformers don't need this manually)\n",
    "df['lstm_summary'] = df['cleaned_summary'].apply(lambda x: '_START_ ' + x + ' _END_')\n",
    "\n",
    "# Drop Empty\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Filter by Length (Crucial for LSTM stability)\n",
    "max_text_len = 80\n",
    "max_summary_len = 15\n",
    "\n",
    "cleaned_text = np.array(df['cleaned_text'])\n",
    "cleaned_summary = np.array(df['cleaned_summary'])\n",
    "lstm_summary = np.array(df['lstm_summary'])\n",
    "\n",
    "short_text = []\n",
    "short_summary = []\n",
    "short_lstm_summary = []\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_text[i].split()) <= max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        short_lstm_summary.append(lstm_summary[i])\n",
    "        \n",
    "df_final = pd.DataFrame({'text': short_text, 'summary': short_summary, 'lstm_summary': short_lstm_summary})\n",
    "print(f\"Final Dataset Size: {len(df_final)}\")\n",
    "\n",
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(\n",
    "    np.array(df_final['text']),\n",
    "    np.array(df_final['lstm_summary']),\n",
    "    test_size=0.1,\n",
    "    random_state=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# For T5, we need the raw summary (no start/end tokens)\n",
    "_, _, y_tr_t5, y_val_t5 = train_test_split(\n",
    "    np.array(df_final['text']),\n",
    "    np.array(df_final['summary']),\n",
    "    test_size=0.1,\n",
    "    random_state=0,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f135ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 20:59:25.464079: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-12-06 20:59:25.464165: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-12-06 20:59:25.464169: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-12-06 20:59:25.464336: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-06 20:59:25.464348: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,321,300</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">962,400</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,137,100</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,682,400</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">18,853,971</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">31371</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │  \u001b[38;5;34m7,321,300\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m600\u001b[0m), │    \u001b[38;5;34m962,400\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │  \u001b[38;5;34m3,137,100\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,682,400\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m600\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m600\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m600\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m18,853,971\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m31371\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,957,171</span> (121.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,957,171\u001b[0m (121.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,957,171</span> (121.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,957,171\u001b[0m (121.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Tokenization ---\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "y_tokenizer = Tokenizer() \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "# Convert to Sequences\n",
    "x_tr_seq = x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "y_tr_seq = y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_val)\n",
    "\n",
    "# Padding\n",
    "x_tr = pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val = pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "y_tr = pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# Vocab Sizes\n",
    "x_voc = len(x_tokenizer.word_index) + 1\n",
    "y_voc = len(y_tokenizer.word_index) + 1\n",
    "\n",
    "# --- Model Architecture ---\n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
    "\n",
    "# Bi-Directional LSTM (More robust than single direction)\n",
    "encoder_lstm = tf.keras.layers.Bidirectional(LSTM(latent_dim, return_sequences=True, return_state=True))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Concatenate states for decoder\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# We need to double latent_dim for decoder because encoder was bidirectional\n",
    "decoder_lstm = LSTM(latent_dim * 2, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense Output\n",
    "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model_lstm = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model_lstm.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model_lstm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e37c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 20:59:26.680068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 867ms/step - accuracy: 0.3038 - loss: 5.9945 - val_accuracy: 0.3666 - val_loss: 5.2104\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Training ---\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "history_lstm = model_lstm.fit(\n",
    "    [x_tr, y_tr[:,:-1]], \n",
    "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:,1:],\n",
    "    epochs=1, # Increase for better results\n",
    "    callbacks=[es],\n",
    "    batch_size=128, \n",
    "    validation_data=([x_val, y_val[:,:-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:,1:])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbce2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerate version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "print(f\"Accelerate version: {accelerate.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9907797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd72d3950dff4858a09cbbb8cb7e95b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e294c3f0854032884259912735d09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training T5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 03:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.668100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=2.5769539388020832, metrics={'train_runtime': 203.7701, 'train_samples_per_second': 29.445, 'train_steps_per_second': 3.681, 'total_flos': 126882938880000.0, 'train_loss': 2.5769539388020832, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # --- Prepare Data for HuggingFace ---\n",
    "# # Ensure accelerate and transformers[torch] are installed so Trainer can run without ImportError\n",
    "# # (Using %pip ensures the install happens in the same Jupyter environment/kernel)\n",
    "# %pip install \"accelerate>=0.26.0\" \"transformers[torch]\" -q\n",
    "\n",
    "# Ensure raw-text splits for T5 exist (create/recreate them from df_final)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Recreate raw splits for T5 (these are raw text and summaries)\n",
    "x_tr_t5, x_val_t5, y_tr_t5, y_val_t5 = train_test_split(\n",
    "    np.array(df_final['text']),\n",
    "    np.array(df_final['summary']),\n",
    "    test_size=0.1,\n",
    "    random_state=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create a small subset for demonstration (use full dataset for final experiments)\n",
    "train_df = pd.DataFrame({'text': x_tr_t5[:2000], 'summary': y_tr_t5[:2000]})\n",
    "val_df = pd.DataFrame({'text': x_val_t5[:500], 'summary': y_val_t5[:500]})\n",
    "\n",
    "# Build HuggingFace datasets directly from these splits\n",
    "hf_train_dataset = Dataset.from_dict({\"text\": train_df['text'].tolist(), \"summary\": train_df['summary'].tolist()})\n",
    "hf_val_dataset = Dataset.from_dict({\"text\": val_df['text'].tolist(), \"summary\": val_df['summary'].tolist()})\n",
    "dataset = DatasetDict({\"train\": hf_train_dataset, \"validation\": hf_val_dataset})\n",
    "\n",
    "# --- T5 Tokenization & Setup ---\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer_t5 = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"summarize: \" + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer_t5(inputs, max_length=max_text_len, truncation=True)\n",
    "    labels = tokenizer_t5(text_target=examples[\"summary\"], max_length=max_summary_len, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# --- T5 Training ---\n",
    "model_t5 = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer_t5, model=model_t5)\n",
    "\n",
    "# Some transformers versions don't support the 'evaluation_strategy' kwarg.\n",
    "# Use do_eval=True (and optionally eval_steps) to enable evaluation instead.\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5-news-summary\",\n",
    "    do_eval=True,\n",
    "    # eval_steps=500,         # Uncomment and set if you want periodic evaluation\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, # Set to True if using GPU\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model_t5,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer_t5,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Training T5...\")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c8e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b0fa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Dictionaries to convert back to text ---\n",
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index\n",
    "\n",
    "# --- 2. Build Inference Models ---\n",
    "# The training model is one big block. For inference, we need to break it apart.\n",
    "\n",
    "# A. Encode the input sequence to get the feature vector\n",
    "encoder_model_inf = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# B. Setup the Decoder for inference\n",
    "# The decoder needs to accept the states (h and c) from the previous step\n",
    "decoder_state_input_h = Input(shape=(latent_dim * 2,)) # *2 because of Bi-Directional LSTM\n",
    "decoder_state_input_c = Input(shape=(latent_dim * 2,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim * 2)) \n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "# Final Decoder model\n",
    "decoder_model_inf = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "# --- 3. The Decode Sequence Function ---\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model_inf.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['_START_']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model_inf.predict([target_seq] + [e_h, e_c], verbose=0)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        # Handle cases where the index might not be in the dictionary (rare edge case)\n",
    "        try:\n",
    "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        except:\n",
    "            sampled_token = \"unknown\"\n",
    "\n",
    "        if(sampled_token != '_END_'):\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == '_END_' or len(decoded_sentence.split()) >= (max_summary_len - 1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "# --- 4. Helper to convert Integer Sequence back to Summary (Ref) ---\n",
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if((i != 0 and i != target_word_index['_START_']) and i != target_word_index['_END_']):\n",
    "            newString = newString + reverse_target_word_index[i] + ' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if(i != 0):\n",
    "            newString = newString + reverse_source_word_index[i] + ' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b64245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lovishbhatia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/lovishbhatia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/lovishbhatia/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LSTM...\n",
      "Evaluating T5...\n",
      "Generating summaries on cpu...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d405cea35884eaeb35620a9594d4dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21b622b5f8e44079f9cf176f63e1b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e5ac3d1b0f468fabed0ccef0bb672a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e26face525f4023ace317a2335abf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4129a608444085b4f8de023ea02f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d66e3de5e7945d2869bc9d4e9e93c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model   ROUGE-1   ROUGE-2   ROUGE-L  BERTScore  Latency(s)\n",
      "0   Bi-LSTM  0.056593  0.000000  0.052160   0.781973    0.405129\n",
      "1  T5-Small  0.322554  0.143849  0.302534   0.871127    0.146859\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Metrics\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "meteor = evaluate.load('meteor') # Requires NLTK download, can add if needed\n",
    "\n",
    "# -------------------------\n",
    "# LSTM Inference Utilities\n",
    "# -------------------------\n",
    "# Build inference encoder & decoder models from trained training-time layers.\n",
    "# These layer variables (encoder_inputs, dec_emb_layer, decoder_lstm, decoder_dense,\n",
    "# latent_dim, etc.) are defined in earlier cells, so reuse them here.\n",
    "\n",
    "from tensorflow.keras import Input as KInput\n",
    "\n",
    "# Encoder inference model: takes encoder input and returns concatenated states\n",
    "# (state_h, state_c) that were created during training (state sizes are latent_dim*2).\n",
    "try:\n",
    "    encoder_model = Model(encoder_inputs, [state_h, state_c])\n",
    "except Exception:\n",
    "    # If those symbols are not in scope, raise a clear error\n",
    "    raise RuntimeError(\"Required LSTM training objects (encoder_inputs/state_h/state_c) not found in scope.\")\n",
    "\n",
    "# Decoder inference model: single-step decoder for generating tokens one by one.\n",
    "decoder_state_input_h = KInput(shape=(latent_dim * 2,))\n",
    "decoder_state_input_c = KInput(shape=(latent_dim * 2,))\n",
    "decoder_single_input = KInput(shape=(1,))\n",
    "\n",
    "# Reuse the same embedding layer\n",
    "dec_emb_single = dec_emb_layer(decoder_single_input)\n",
    "\n",
    "# Run LSTM step\n",
    "decoder_outputs_single, decoder_state_h_single, decoder_state_c_single = decoder_lstm(\n",
    "    dec_emb_single, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
    ")\n",
    "\n",
    "# Project to vocab\n",
    "decoder_outputs_single = decoder_dense(decoder_outputs_single)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_single_input, decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs_single, decoder_state_h_single, decoder_state_c_single]\n",
    ")\n",
    "\n",
    "# Helper to convert a sequence of token ids to a cleaned summary string\n",
    "def seq2summary(seq):\n",
    "    # If seq is already text, return it\n",
    "    if isinstance(seq, str):\n",
    "        return seq\n",
    "    # If seq is a sequence of ids (padded), map to words\n",
    "    words = []\n",
    "    for idx in np.array(seq).astype(int).tolist():\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        w = y_tokenizer.index_word.get(idx, '')\n",
    "        if not w:\n",
    "            continue\n",
    "        # remove start/end tokens if present\n",
    "        if w.lower() in ('_start_', '_end_', '_start', '_end'):\n",
    "            continue\n",
    "        words.append(w)\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Core decode_sequence function for the trained Bi-LSTM seq2seq model\n",
    "def decode_sequence(input_seq):\n",
    "    \"\"\"\n",
    "    input_seq: numpy array shape (1, max_text_len) of token ids (padded).\n",
    "    Returns: decoded summary string (without start/end tokens).\n",
    "    \"\"\"\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    # states_value is [state_h, state_c]\n",
    "\n",
    "    # Prepare target sequence with the start token id\n",
    "    start_id = None\n",
    "    # try common start token text variants first\n",
    "    for key in ('_start_', '_START_', '_start', '_START', 'start', '<start>', '<s>', '[START]'):\n",
    "        if key in y_tokenizer.word_index:\n",
    "            start_id = y_tokenizer.word_index[key]\n",
    "            break\n",
    "\n",
    "    # fallback: many tokenizers use index 2 for the <start> token (see y_tr/y_val),\n",
    "    # or index 1; try to infer from tokenizer index_word if available\n",
    "    if start_id is None:\n",
    "        if 2 in getattr(y_tokenizer, \"index_word\", {}):\n",
    "            start_id = 2\n",
    "        elif 1 in getattr(y_tokenizer, \"index_word\", {}):\n",
    "            start_id = 1\n",
    "        else:\n",
    "            # attempt to infer from a reference y_val sequence if present\n",
    "            try:\n",
    "                # take first non-zero token from first y_val sequence\n",
    "                first_seq = np.array(y_val[0]).astype(int).tolist()\n",
    "                for t in first_seq:\n",
    "                    if t != 0:\n",
    "                        start_id = int(t)\n",
    "                        break\n",
    "            except Exception:\n",
    "                start_id = None\n",
    "\n",
    "    if start_id is None:\n",
    "        raise ValueError(\"Start token not found in y_tokenizer.word_index and could not be inferred. \"\n",
    "                         \"Ensure your target tokenizer includes a start token or that y_val is available to infer it.\")\n",
    "\n",
    "    target_seq = np.array([[start_id]])\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_words = []\n",
    "    iter_count = 0\n",
    "\n",
    "    while not stop_condition and iter_count < max_summary_len:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq, states_value[0], states_value[1]], verbose=0)\n",
    "        # output_tokens shape: (1, 1, vocab_size)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = y_tokenizer.index_word.get(sampled_token_index, '')\n",
    "\n",
    "        # If token not found or it's an end token, stop.\n",
    "        if not sampled_word or sampled_word.lower() in ('_end_', '_end', 'end', '<end>', '</s>'):\n",
    "            break\n",
    "\n",
    "        decoded_words.append(sampled_word)\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        iter_count += 1\n",
    "\n",
    "    return \" \".join(decoded_words).strip()\n",
    "\n",
    "def generate_lstm_predictions(input_data, count=100):\n",
    "    # input_data expected to be padded sequences (numpy array of shape (N, max_text_len))\n",
    "    preds = []\n",
    "    refs = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(count):\n",
    "        pred = decode_sequence(input_data[i].reshape(1, max_text_len))\n",
    "        preds.append(pred.replace(\"_START_\", \"\").replace(\"_END_\", \"\").strip())\n",
    "        \n",
    "        # Get Reference: handle both sequences and raw strings\n",
    "        ref = seq2summary(y_val[i]) if 'y_val' in globals() else \"\"\n",
    "        refs.append(ref.replace(\"_START_\", \"\").replace(\"_END_\", \"\").strip())\n",
    "        \n",
    "    end_time = time.time()\n",
    "    return preds, refs, (end_time - start_time)/count\n",
    "\n",
    "def generate_t5_predictions(dataset, count=100):\n",
    "    # 1. Force Model to CPU to avoid the MPS Embedding Bug\n",
    "    device = \"cpu\"\n",
    "    model_t5.to(device) \n",
    "    \n",
    "    inputs = dataset['text'][:count]\n",
    "    refs = dataset['summary'][:count]\n",
    "    preds = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Generating summaries on {device}...\")\n",
    "    \n",
    "    for text in inputs:\n",
    "        # 2. Ensure inputs are also sent to CPU\n",
    "        input_ids = tokenizer_t5(\"summarize: \" + text, return_tensors=\"pt\").input_ids.to(device)\n",
    "        \n",
    "        # Generate\n",
    "        outputs = model_t5.generate(input_ids, max_length=max_summary_len)\n",
    "        preds.append(tokenizer_t5.decode(outputs[0], skip_special_tokens=True))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return preds, refs, (end_time - start_time)/count\n",
    "\n",
    "# --- Run Comparison ---\n",
    "sample_size = 50 # Use 500+ for final paper\n",
    "\n",
    "print(\"Evaluating LSTM...\")\n",
    "lstm_preds, lstm_refs, lstm_latency = generate_lstm_predictions(x_val, sample_size)\n",
    "\n",
    "print(\"Evaluating T5...\")\n",
    "t5_preds, t5_refs, t5_latency = generate_t5_predictions(hf_val_dataset, sample_size)\n",
    "\n",
    "# --- Compute Metrics ---\n",
    "results = {'Model': [], 'ROUGE-1': [], 'ROUGE-2': [], 'ROUGE-L': [], 'BERTScore': [], 'Latency(s)': []}\n",
    "\n",
    "# 1. ROUGE\n",
    "lstm_rouge = rouge.compute(predictions=lstm_preds, references=lstm_refs)\n",
    "t5_rouge = rouge.compute(predictions=t5_preds, references=t5_refs)\n",
    "\n",
    "# 2. BERTScore (Semantic Similarity)\n",
    "lstm_bert = bertscore.compute(predictions=lstm_preds, references=lstm_refs, lang=\"en\")\n",
    "t5_bert = bertscore.compute(predictions=t5_preds, references=t5_refs, lang=\"en\")\n",
    "\n",
    "# Populate Data\n",
    "results['Model'] = ['Bi-LSTM', 'T5-Small']\n",
    "results['ROUGE-1'] = [lstm_rouge['rouge1'], t5_rouge['rouge1']]\n",
    "results['ROUGE-2'] = [lstm_rouge['rouge2'], t5_rouge['rouge2']]\n",
    "results['ROUGE-L'] = [lstm_rouge['rougeL'], t5_rouge['rougeL']]\n",
    "results['BERTScore'] = [np.mean(lstm_bert['f1']), np.mean(t5_bert['f1'])]\n",
    "results['Latency(s)'] = [lstm_latency, t5_latency]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# --- Visualization ---\n",
    "# Normalize metrics for plotting\n",
    "df_melt = results_df.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Metric\", y=\"Score\", hue=\"Model\", data=df_melt)\n",
    "plt.title(\"Comparative Analysis: Bi-LSTM vs T5 (Performance Metrics)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c607539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
